import os
import time
import random
import numpy as np
import matplotlib.pyplot as plt

from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
import torchvision.transforms.functional as TF

import segmentation_models_pytorch as smp
from tqdm import tqdm

# --------------------------------------------------------------------------------
# 1) .npy 파일 로드 & 전처리
# --------------------------------------------------------------------------------
# Windows 경로 설정 시 raw string 사용
prefix = r"C:/Users/hojoo/Downloads/covid-segmentation"

images_radiopedia = np.load(os.p454545 ath.join(prefix, 'images_radiopedia.npy')).astype(np.float32)
masks_radiopedia  = np.load(os.path.join(prefix, 'masks_radiopedia.npy')).astype(np.int8)
images_medseg     = np.load(os.path.join(prefix, 'images_medseg.npy')).astype(np.float32)
masks_medseg      = np.load(os.path.join(prefix, 'masks_medseg.npy')).astype(np.int8)

print("radiopedia:", images_radiopedia.shape, masks_radiopedia.shape)
print("medseg:    ", images_medseg.shape,    masks_medseg.shape)

# one-hot to mask index
masks_radiopedia = np.argmax(masks_radiopedia, axis=-1)
masks_medseg     = np.argmax(masks_medseg, axis=-1)

def preprocess(images, mean_std=None):
    images = np.clip(images, -1500, 500)
    p5, p95 = np.percentile(images, [5,95])
    valid = images[(images>=p5)&(images<=p95)]
    if mean_std is None:
        mean, std = valid.mean(), valid.std()
    else:
        mean, std = mean_std
    return (images-mean)/std, (mean, std)

images_radiopedia, mean_std = preprocess(images_radiopedia)
images_medseg, _             = preprocess(images_medseg, mean_std)

# --------------------------------------------------------------------------------
# 2) Transform 정의
# --------------------------------------------------------------------------------
def strong_transform(img, mask, size=384):
    angle = random.uniform(-30,30)
    img = TF.rotate(img, angle)
    mask = TF.rotate(mask, angle)
    if random.random()<0.5:
        img = TF.adjust_brightness(img, random.uniform(0.7,1.3))
        img = TF.adjust_contrast(img,   random.uniform(0.7,1.3))
    if random.random()<0.5:
        img = TF.hflip(img)
        mask = TF.hflip(mask)
    img = TF.center_crop(img, (size, size))
    mask= TF.center_crop(mask,(size,size))
    return img, mask

def simple_resize(img, mask, size=384):
    img  = TF.resize(img, (size,size), interpolation=Image.BILINEAR)
    mask = TF.resize(mask,(size,size), interpolation=Image.NEAREST)
    return img, mask

# --------------------------------------------------------------------------------
# 3) Dataset 정의
# --------------------------------------------------------------------------------
class SegDataset(Dataset):
    def __init__(self, images, masks, transform=None):
        self.images    = images
        self.masks     = masks
        self.transform = transform
        self.mean = [0.485,0.456,0.406]
        self.std  = [0.229,0.224,0.225]

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img = self.images[idx]
        msk = self.masks[idx]

        # 1) 채널 보장
        if img.ndim == 2:
            img = np.stack([img] * 3, axis=-1)
        elif img.ndim == 3 and img.shape[-1] == 1:
            img = np.concatenate([img] * 3, axis=-1)
        elif not (img.ndim == 3 and img.shape[-1] == 3):
            raise ValueError(f"Unexpected image shape: {img.shape}")

        # 2) uint8 변환 및 PIL 생성
        img = (img * 255).clip(0, 255).astype(np.uint8)
        pil_img = Image.fromarray(img, mode='RGB')

        # 3) 마스크 처리
        if msk.ndim != 2:
            msk = np.squeeze(msk)
        msk_uint8 = msk.astype(np.uint8)
        pil_msk   = Image.fromarray(msk_uint8, mode='L')

        # 4) 증강 적용
        if self.transform:
            pil_img, pil_msk = self.transform(pil_img, pil_msk)

        # 5) Tensor 변환 및 정규화
        t_img = T.ToTensor()(pil_img)
        t_img = T.Normalize(self.mean, self.std)(t_img)

        # 6) 마스크 Tensor
        arr_msk = np.array(pil_msk)
        if arr_msk.ndim == 3:
            arr_msk = arr_msk[:,:,0]
        t_msk = torch.from_numpy(arr_msk).long()

        return t_img, t_msk

# DataLoader 준비
batch_size = 2
train_idx   = list(range(24, images_medseg.shape[0]))
val_idx     = list(range(24))
train_images = np.concatenate([images_medseg[train_idx], images_radiopedia],axis=0)
train_masks  = np.concatenate([masks_medseg[train_idx],   masks_radiopedia],axis=0)
val_images   = images_medseg[val_idx]
val_masks    = masks_medseg[val_idx]

train_ds = SegDataset(train_images, train_masks, transform=strong_transform)
val_ds   = SegDataset(val_images,   val_masks,   transform=lambda i,m: simple_resize(i,m,384))
train_dl = DataLoader(train_ds, batch_size, shuffle=True)
val_dl   = DataLoader(val_ds,   batch_size, shuffle=False)

# --------------------------------------------------------------------------------
# 4) Metrics 정의
# --------------------------------------------------------------------------------
def pixel_accuracy(logits, mask):
    pred = logits.argmax(dim=1)
    return (pred==mask).float().mean().item()

def mIoU(logits, mask, classes=4):
    pred_flat = logits.argmax(1).view(-1)
    mask_flat = mask.view(-1)
    ious = []
    for c in range(classes):
        pred_c = pred_flat==c
        mask_c = mask_flat==c
        if mask_c.sum().item()==0:
            continue
        inter = (pred_c & mask_c).sum().item()
        uni   = (pred_c | mask_c).sum().item()
        ious.append(inter/uni)
    return np.mean(ious)

def precision_recall_f1(logits, mask, classes=4):
    pred_flat = logits.argmax(1).view(-1)
    mask_flat = mask.view(-1)
    precs, recs = [], []
    for c in range(classes):
        tp = ((pred_flat==c)&(mask_flat==c)).sum().item()
        fp = ((pred_flat==c)&(mask_flat!=c)).sum().item()
        fn = ((pred_flat!=c)&(mask_flat==c)).sum().item()
        if tp+fp>0: precs.append(tp/(tp+fp))
        if tp+fn>0: recs.append(tp/(tp+fn))
    prec = np.mean(precs) if precs else 0
    rec  = np.mean(recs) if recs else 0
    f1   = 2*prec*rec/(prec+rec) if prec+rec>0 else 0
    return prec, rec, f1

# --------------------------------------------------------------------------------
# 5) Model & Training Loop
# --------------------------------------------------------------------------------
model = smp.Unet('efficientnet-b4', in_channels=3, classes=4, activation=None)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer, max_lr=1e-3, epochs=10, steps_per_epoch=len(train_dl)
)

def fit(epochs):
    best_loss = float('inf')
    for e in range(epochs):
        model.train()
        train_stats = {'loss':0,'acc':0,'iou':0,'prec':0,'rec':0,'f1':0}
        for imgs, msks in tqdm(train_dl, desc=f"Train Epoch {e+1}"):
            imgs, msks = imgs.to(device), msks.to(device)
            optimizer.zero_grad()
            logits = model(imgs)
            loss = criterion(logits, msks)
            loss.backward()
            optimizer.step()
            scheduler.step()
            train_stats['loss'] += loss.item()
            train_stats['acc'] += pixel_accuracy(logits, msks)
            train_stats['iou'] += mIoU(logits, msks)
            p, r, f = precision_recall_f1(logits, msks)
            train_stats['prec'] += p
            train_stats['rec'] += r
            train_stats['f1'] += f
        for k in train_stats:
            train_stats[k] /= len(train_dl)

        model.eval()
        val_stats = {'loss':0,'acc':0,'iou':0,'prec':0,'rec':0,'f1':0}
        with torch.no_grad():
            for imgs, msks in tqdm(val_dl, desc=f"Val Epoch {e+1}"):
                imgs, msks = imgs.to(device), msks.to(device)
                logits = model(imgs)
                loss = criterion(logits, msks)
                val_stats['loss'] += loss.item()
                val_stats['acc'] += pixel_accuracy(logits, msks)
                val_stats['iou'] += mIoU(logits, msks)
                p, r, f = precision_recall_f1(logits, msks)
                val_stats['prec'] += p
                val_stats['rec'] += r
                val_stats['f1'] += f
        for k in val_stats:
            val_stats[k] /= len(val_dl)

        print(f"Epoch {e+1}/{epochs}")
        print(f" Train | Loss: {train_stats['loss']:.3f} | Acc: {train_stats['acc']:.3f} | mIoU: {train_stats['iou']:.3f} | Prec: {train_stats['prec']:.3f} | Rec: {train_stats['rec']:.3f} | F1: {train_stats['f1']:.3f}")
        print(f" Val   | Loss: {val_stats['loss']:.3f} | Acc: {val_stats['acc']:.3f} | mIoU: {val_stats['iou']:.3f} | Prec: {val_stats['prec']:.3f} | Rec: {val_stats['rec']:.3f} | F1: {val_stats['f1']:.3f}\n")

    if val_stats['loss'] < best_loss:
        torch.save(model.state_dict(), f"best_model_epoch{e+1}.pth")

# --------------------------------------------------------------------------------
# 6) 학습 실행
# --------------------------------------------------------------------------------
if __name__ == "__main__":
    fit(10)
