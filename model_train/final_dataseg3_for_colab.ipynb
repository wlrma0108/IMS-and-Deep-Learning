{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-RdvOb1a6c0m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "68liGF32JeCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d2eaeb-1255-4806-8f94-e512c3cbd325"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 설정 ---\n",
        "IMAGE_DIR    = r'/content/drive/MyDrive/dataset2_aug_dire/origin_and_gan_and_elastic'\n",
        "MASK_DIR     = r'/content/drive/MyDrive/dataset2_aug_dire/origin_and_gan_and_elastic_masks'\n",
        "IMAGE_SIZE   = 256\n",
        "NUM_SAMPLES  = 2700\n",
        "BATCH_SIZE   = 8\n",
        "EPOCHS       = 50\n",
        "LEARNING_RATE= 1e-3\n",
        "DEVICE       = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "RESULTS_DIR  = '/content/drive/MyDrive/results_origin_and_gan_50'\n",
        "PLOTS_DIR    = os.path.join(RESULTS_DIR, 'plots')\n",
        "METRICS_FILE = os.path.join(RESULTS_DIR, 'metrics.txt')\n",
        "\n",
        "print(f\"사용중인 장치 : {DEVICE}\")\n",
        "\n",
        "# --- 결과 폴더 생성 ---\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
        "\n",
        "# --- Dataset 클래스 ---\n",
        "class CovidDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, samples=None):\n",
        "        # 이미지 파일 리스트\n",
        "        all_imgs = sorted(os.listdir(image_dir))\n",
        "        # 만약 특정 샘플 목록을 받았다면, 그 중 실제 존재하는 것만 필터링\n",
        "        if samples is None:\n",
        "            self.files = [f for f in all_imgs]\n",
        "        else:\n",
        "            self.files = [f for f in samples if f in all_imgs]\n",
        "\n",
        "        if not self.files:\n",
        "            raise RuntimeError(f\"No image files found in {image_dir}\")\n",
        "\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir  = mask_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]  # e.g. \"frame_0853.png\"\n",
        "        img_path = os.path.join(self.image_dir, fname)\n",
        "        # frame_0853.png → mask_0853.png\n",
        "        mask_fname = fname.replace('frame_', 'mask_')\n",
        "        mask_path  = os.path.join(self.mask_dir, mask_fname)\n",
        "\n",
        "        # --- 이미지 읽기 & 체크 ---\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Cannot read image: {img_path}\")\n",
        "\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"Cannot read mask:  {mask_path}\")\n",
        "\n",
        "        # --- 리사이즈 & 전처리 ---\n",
        "        img  = cv2.resize(img,  (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        img  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "        img  = np.transpose(img, (2, 0, 1))\n",
        "\n",
        "        mask = cv2.resize(mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "        mask = mask.astype(np.float32) / 255.0\n",
        "        mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "        return torch.tensor(img), torch.tensor(mask)\n",
        "\n",
        "# --- UNet 모델 ---\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc1 = ConvBlock(3, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = ConvBlock(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = ConvBlock(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = ConvBlock(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bridge = ConvBlock(512, 1024)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.dec1 = ConvBlock(1024, 512)\n",
        "        self.up2 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec2 = ConvBlock(512, 256)\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec3 = ConvBlock(256, 128)\n",
        "        self.up4 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec4 = ConvBlock(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1 = self.enc1(x); p1 = self.pool1(s1)\n",
        "        s2 = self.enc2(p1); p2 = self.pool2(s2)\n",
        "        s3 = self.enc3(p2); p3 = self.pool3(s3)\n",
        "        s4 = self.enc4(p3); p4 = self.pool4(s4)\n",
        "        b  = self.bridge(p4)\n",
        "        d1 = self.up1(b);   d1 = torch.cat([d1, s4], dim=1); d1 = self.dec1(d1)\n",
        "        d2 = self.up2(d1);  d2 = torch.cat([d2, s3], dim=1); d2 = self.dec2(d2)\n",
        "        d3 = self.up3(d2);  d3 = torch.cat([d3, s2], dim=1); d3 = self.dec3(d3)\n",
        "        d4 = self.up4(d3);  d4 = torch.cat([d4, s1], dim=1); d4 = self.dec4(d4)\n",
        "        return torch.sigmoid(self.out(d4))\n",
        "\n",
        "# --- Metric 계산 함수 ---\n",
        "def calculate_metrics(preds, masks, threshold=0.5):\n",
        "    preds = (preds > threshold).float()\n",
        "    masks = (masks > 0.5).float()\n",
        "    intersection = (preds * masks).sum(dim=(1, 2, 3))\n",
        "    union        = ((preds + masks) > 0).float().sum(dim=(1, 2, 3))\n",
        "    iou          = (intersection + 1e-7) / (union + 1e-7)\n",
        "    miou         = iou.mean().item()\n",
        "\n",
        "    tp    = intersection\n",
        "    fp    = (preds * (1 - masks)).sum(dim=(1, 2, 3))\n",
        "    fn    = ((1 - preds) * masks).sum(dim=(1, 2, 3))\n",
        "    precision = tp / (tp + fp + 1e-7)\n",
        "    recall    = tp / (tp + fn + 1e-7)\n",
        "    f1        = (2 * precision * recall) / (precision + recall + 1e-7)\n",
        "    f1_mean   = f1.mean().item()\n",
        "\n",
        "    return f1_mean, miou\n",
        "\n",
        "# --- Train & Eval ---\n",
        "def train_model(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, masks in loader:\n",
        "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "        preds = model(imgs)\n",
        "        loss  = criterion(preds, masks)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "def eval_model(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    f1_scores, ious = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in loader:\n",
        "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "            preds = model(imgs)\n",
        "            loss  = criterion(preds, masks)\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            f1, miou = calculate_metrics(preds, masks)\n",
        "            f1_scores.append(f1); ious.append(miou)\n",
        "    return running_loss / len(loader.dataset), np.mean(f1_scores), np.mean(ious)\n",
        "\n",
        "# --- 시각화 및 저장 ---\n",
        "def plot_history(history):\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    plt.figure(figsize=(15, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
        "    plt.plot(epochs, history['val_loss'],   label='Val Loss')\n",
        "    plt.title('Loss'); plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(epochs, history['val_f1'],     label='Val F1')\n",
        "    plt.title('F1 Score'); plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(epochs, history['val_miou'],   label='Val mIoU')\n",
        "    plt.title('mIoU'); plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(PLOTS_DIR, 'training_history.png')\n",
        "    plt.savefig(save_path)\n",
        "    print(f'학습 곡선이 저장되었습니다: {save_path}')\n",
        "    plt.close()\n",
        "\n",
        "# --- 메인 실행 ---\n",
        "if __name__ == '__main__':\n",
        "    # 데이터 분할\n",
        "    files     = os.listdir(IMAGE_DIR)[:NUM_SAMPLES]\n",
        "    train_val, test = train_test_split(files, test_size=0.2, random_state=42)\n",
        "    train, val      = train_test_split(train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "    # Dataset & DataLoader\n",
        "    train_loader = DataLoader(CovidDataset(IMAGE_DIR, MASK_DIR, train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader   = DataLoader(CovidDataset(IMAGE_DIR, MASK_DIR, val),   batch_size=BATCH_SIZE)\n",
        "    test_loader  = DataLoader(CovidDataset(IMAGE_DIR, MASK_DIR, test),  batch_size=BATCH_SIZE)\n",
        "\n",
        "    # 모델/옵티마이저/손실함수\n",
        "    model     = UNet().to(DEVICE)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # 학습 루프\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_f1': [], 'val_miou': []}\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_loss                = train_model(model, train_loader, criterion, optimizer)\n",
        "        val_loss, val_f1, val_miou = eval_model(model, val_loader,   criterion)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        history['val_miou'].append(val_miou)\n",
        "\n",
        "        print(f'Epoch {epoch}/{EPOCHS} | Train Loss: {train_loss:.4f} | '\n",
        "              f'Val Loss: {val_loss:.4f} | F1: {val_f1:.4f} | mIoU: {val_miou:.4f}')\n",
        "\n",
        "    # 모델 저장\n",
        "    torch.save(model.state_dict(), os.path.join(RESULTS_DIR, 'ela_unet_covid_segmentation.pt'))\n",
        "\n",
        "    # 학습 곡선 저장\n",
        "    plot_history(history)\n",
        "\n",
        "    # 테스트 데이터 평가\n",
        "    test_loss, test_f1, test_miou = eval_model(model, test_loader, criterion)\n",
        "    metrics_text = (\n",
        "        f\"Test Loss : {test_loss:.4f}\\n\"\n",
        "        f\"Test F1   : {test_f1:.4f}\\n\"\n",
        "        f\"Test mIoU : {test_miou:.4f}\\n\"\n",
        "    )\n",
        "    with open(METRICS_FILE, 'w') as f:\n",
        "        f.write(\"=== Test Results ===\\n\")\n",
        "        f.write(metrics_text)\n",
        "    print(metrics_text)\n",
        "    print(f'테스트 결과가 저장되었습니다: {METRICS_FILE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmP6YRdPJ-BU",
        "outputId": "8b1a8bb8-9539-4dbd-8bb2-382ff3f894fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용중인 장치 : cuda\n",
            "Epoch 1/50 | Train Loss: 0.1632 | Val Loss: 0.0674 | F1: 0.0000 | mIoU: 0.0040\n",
            "Epoch 2/50 | Train Loss: 0.0498 | Val Loss: 0.5243 | F1: 0.0649 | mIoU: 0.0377\n",
            "Epoch 3/50 | Train Loss: 0.0326 | Val Loss: 0.0424 | F1: 0.2381 | mIoU: 0.1778\n",
            "Epoch 4/50 | Train Loss: 0.0248 | Val Loss: 0.0234 | F1: 0.4213 | mIoU: 0.3286\n",
            "Epoch 5/50 | Train Loss: 0.0224 | Val Loss: 0.2402 | F1: 0.2189 | mIoU: 0.1462\n",
            "Epoch 6/50 | Train Loss: 0.0198 | Val Loss: 0.0190 | F1: 0.5011 | mIoU: 0.4055\n",
            "Epoch 7/50 | Train Loss: 0.0194 | Val Loss: 0.0187 | F1: 0.5103 | mIoU: 0.4128\n",
            "Epoch 8/50 | Train Loss: 0.0171 | Val Loss: 0.0158 | F1: 0.5977 | mIoU: 0.4866\n",
            "Epoch 9/50 | Train Loss: 0.0163 | Val Loss: 0.0884 | F1: 0.4239 | mIoU: 0.3330\n",
            "Epoch 10/50 | Train Loss: 0.0150 | Val Loss: 0.0129 | F1: 0.6600 | mIoU: 0.5466\n",
            "Epoch 11/50 | Train Loss: 0.0154 | Val Loss: 0.0126 | F1: 0.6937 | mIoU: 0.5790\n",
            "Epoch 12/50 | Train Loss: 0.0137 | Val Loss: 0.0146 | F1: 0.6533 | mIoU: 0.5358\n",
            "Epoch 13/50 | Train Loss: 0.0126 | Val Loss: 0.0125 | F1: 0.6430 | mIoU: 0.5318\n",
            "Epoch 14/50 | Train Loss: 0.0125 | Val Loss: 0.0145 | F1: 0.7152 | mIoU: 0.5959\n",
            "Epoch 15/50 | Train Loss: 0.0110 | Val Loss: 0.0115 | F1: 0.6826 | mIoU: 0.5649\n",
            "Epoch 16/50 | Train Loss: 0.0107 | Val Loss: 0.0108 | F1: 0.7421 | mIoU: 0.6305\n",
            "Epoch 17/50 | Train Loss: 0.0104 | Val Loss: 0.0281 | F1: 0.6019 | mIoU: 0.4976\n",
            "Epoch 18/50 | Train Loss: 0.0099 | Val Loss: 0.0198 | F1: 0.6638 | mIoU: 0.5592\n",
            "Epoch 19/50 | Train Loss: 0.0093 | Val Loss: 0.0100 | F1: 0.7572 | mIoU: 0.6473\n",
            "Epoch 20/50 | Train Loss: 0.0090 | Val Loss: 0.0094 | F1: 0.7444 | mIoU: 0.6389\n",
            "Epoch 21/50 | Train Loss: 0.0091 | Val Loss: 0.0109 | F1: 0.7435 | mIoU: 0.6297\n",
            "Epoch 22/50 | Train Loss: 0.0092 | Val Loss: 0.0115 | F1: 0.6740 | mIoU: 0.5615\n",
            "Epoch 23/50 | Train Loss: 0.0093 | Val Loss: 0.0102 | F1: 0.6848 | mIoU: 0.5850\n",
            "Epoch 24/50 | Train Loss: 0.0081 | Val Loss: 0.0098 | F1: 0.7656 | mIoU: 0.6574\n",
            "Epoch 25/50 | Train Loss: 0.0087 | Val Loss: 0.0168 | F1: 0.6546 | mIoU: 0.5473\n",
            "Epoch 26/50 | Train Loss: 0.0081 | Val Loss: 0.0091 | F1: 0.7640 | mIoU: 0.6564\n",
            "Epoch 27/50 | Train Loss: 0.0079 | Val Loss: 0.0208 | F1: 0.6260 | mIoU: 0.5239\n",
            "Epoch 28/50 | Train Loss: 0.0077 | Val Loss: 0.0098 | F1: 0.7504 | mIoU: 0.6412\n",
            "Epoch 29/50 | Train Loss: 0.0076 | Val Loss: 0.0082 | F1: 0.7802 | mIoU: 0.6762\n",
            "Epoch 30/50 | Train Loss: 0.0070 | Val Loss: 0.0084 | F1: 0.7666 | mIoU: 0.6651\n",
            "Epoch 31/50 | Train Loss: 0.0070 | Val Loss: 0.0082 | F1: 0.7686 | mIoU: 0.6690\n",
            "Epoch 32/50 | Train Loss: 0.0071 | Val Loss: 0.0089 | F1: 0.7693 | mIoU: 0.6646\n",
            "Epoch 33/50 | Train Loss: 0.0068 | Val Loss: 0.0084 | F1: 0.7790 | mIoU: 0.6803\n",
            "Epoch 34/50 | Train Loss: 0.0067 | Val Loss: 0.0094 | F1: 0.7588 | mIoU: 0.6611\n",
            "Epoch 35/50 | Train Loss: 0.0065 | Val Loss: 0.0084 | F1: 0.7800 | mIoU: 0.6798\n",
            "Epoch 36/50 | Train Loss: 0.0061 | Val Loss: 0.0082 | F1: 0.7702 | mIoU: 0.6744\n",
            "Epoch 37/50 | Train Loss: 0.0062 | Val Loss: 0.0083 | F1: 0.7707 | mIoU: 0.6676\n",
            "Epoch 38/50 | Train Loss: 0.0060 | Val Loss: 0.0080 | F1: 0.7904 | mIoU: 0.6929\n",
            "Epoch 39/50 | Train Loss: 0.0058 | Val Loss: 0.0090 | F1: 0.7637 | mIoU: 0.6665\n",
            "Epoch 40/50 | Train Loss: 0.0060 | Val Loss: 0.0086 | F1: 0.7757 | mIoU: 0.6776\n",
            "Epoch 41/50 | Train Loss: 0.0058 | Val Loss: 0.0092 | F1: 0.7782 | mIoU: 0.6738\n",
            "Epoch 42/50 | Train Loss: 0.0057 | Val Loss: 0.0089 | F1: 0.7722 | mIoU: 0.6720\n",
            "Epoch 43/50 | Train Loss: 0.0060 | Val Loss: 0.0093 | F1: 0.7393 | mIoU: 0.6406\n",
            "Epoch 44/50 | Train Loss: 0.0057 | Val Loss: 0.0082 | F1: 0.7851 | mIoU: 0.6901\n",
            "Epoch 45/50 | Train Loss: 0.0055 | Val Loss: 0.0090 | F1: 0.7871 | mIoU: 0.6860\n",
            "Epoch 46/50 | Train Loss: 0.0052 | Val Loss: 0.0079 | F1: 0.7972 | mIoU: 0.7035\n",
            "Epoch 47/50 | Train Loss: 0.0051 | Val Loss: 0.0082 | F1: 0.7848 | mIoU: 0.6901\n",
            "Epoch 48/50 | Train Loss: 0.0051 | Val Loss: 0.0097 | F1: 0.7649 | mIoU: 0.6634\n",
            "Epoch 49/50 | Train Loss: 0.0058 | Val Loss: 0.0089 | F1: 0.7760 | mIoU: 0.6796\n",
            "Epoch 50/50 | Train Loss: 0.0050 | Val Loss: 0.0080 | F1: 0.7944 | mIoU: 0.6972\n",
            "학습 곡선이 저장되었습니다: /content/drive/MyDrive/results_origin_and_gan_50/plots/training_history.png\n",
            "Test Loss : 0.0084\n",
            "Test F1   : 0.7968\n",
            "Test mIoU : 0.7014\n",
            "\n",
            "테스트 결과가 저장되었습니다: /content/drive/MyDrive/results_origin_and_gan_50/metrics.txt\n"
          ]
        }
      ]
    }
  ]
}